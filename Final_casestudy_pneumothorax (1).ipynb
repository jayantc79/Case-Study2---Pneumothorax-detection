{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OXCVx2XrykAp",
    "outputId": "f48ca898-904e-4b33-ab1d-8955a4dc664e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-io\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/3c/b45c30448cd6a04f25b088da024229149323fa44bc6322a7372bb556eada/tensorflow_io-0.17.0-cp36-cp36m-manylinux2010_x86_64.whl (25.3MB)\n",
      "\u001b[K     |████████████████████████████████| 25.3MB 134kB/s \n",
      "\u001b[?25hRequirement already satisfied: tensorflow<2.5.0,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-io) (2.4.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (0.2.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (1.12.1)\n",
      "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (1.15.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (3.3.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (1.19.5)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (3.12.4)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (0.36.2)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (3.7.4.3)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (0.10.0)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (1.1.2)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (1.32.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (2.4.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (1.12)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (0.3.3)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5.0,>=2.4.0->tensorflow-io) (1.6.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (51.1.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (2.23.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (3.3.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (0.4.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (1.17.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (1.7.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (2020.12.5)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (3.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (1.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (4.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (3.4.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5.0,>=2.4.0->tensorflow-io) (0.4.8)\n",
      "Installing collected packages: tensorflow-io\n",
      "Successfully installed tensorflow-io-0.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbCAHzF0ymUP",
    "outputId": "870f93da-eb47-46c2-d180-8d09504ee276"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydicom\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/15/df16546bc59bfca390cf072d473fb2c8acd4231636f64356593a63137e55/pydicom-2.1.2-py3-none-any.whl (1.9MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9MB 13.6MB/s \n",
      "\u001b[?25hInstalling collected packages: pydicom\n",
      "Successfully installed pydicom-2.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aFu82_tw7Gx-",
    "outputId": "a9d75e3e-c362-4d63-98a8-aa5c51cc5c7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jm9LgAX865Gj",
    "outputId": "91ecd3b6-1dc3-4ca0-a5cc-64aa989a473b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "GGtZvcQ26UV7"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "import pydicom as dicom\n",
    "from tqdm.notebook import tqdm\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import tensorflow_io as tfio\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "import time\n",
    "import logging, os\n",
    "from joblib import Parallel, delayed\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "import random, re, math\n",
    "import tensorflow as tf, tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras.applications import ResNet152V2, InceptionResNetV2, InceptionV3, Xception, VGG19\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, Concatenate, Activation, Add, multiply, add, concatenate, LeakyReLU, ZeroPadding2D, UpSampling2D, BatchNormalization, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras import backend as K \n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# imports for building the network\n",
    "from tensorflow import reduce_sum\n",
    "from tensorflow.keras.backend import pow\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, UpSampling2D, Concatenate, Add, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import DenseNet121, ResNet50V2, DenseNet169, InceptionResNetV2,MobileNetV2, NASNetMobile, DenseNet201, NASNetLarge, Xception\n",
    "from tensorflow.keras.layers import Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "CWVKa1YU7T-i"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import glob\n",
    "\n",
    "# reading all dcm files into train and text\n",
    "train = sorted(glob.glob(\"/content/drive/MyDrive/siim-acr-pneumothorax/pneumothorax/dicom-images-train/*/*/*.dcm\"))\n",
    "test = sorted(glob.glob(\"/content/drive/MyDrive/siim-acr-pneumothorax/pneumothorax/dicom-images-test/*/*/*.dcm\"))\n",
    "# reading the csv\n",
    "dataset = pd.read_csv('/content/drive/MyDrive/siim-acr-pneumothorax/pneumothorax/train-rle.csv', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PzZkhK5O8Nzz"
   },
   "outputs": [],
   "source": [
    "import pydicom\n",
    "\n",
    "#dataframe to ease the access\n",
    "patients = []\n",
    "remove=[]\n",
    "pd.reset_option('max_colwidth')\n",
    "\n",
    "for t in train:\n",
    "  data = pydicom.dcmread(t)\n",
    "  patient = {}\n",
    "  patient[\"UID\"] = data.SOPInstanceUID\n",
    "  \n",
    "  try:\n",
    "    encoded_pixels = dataset[dataset[\"ImageId\"] == patient[\"UID\"]].values[0][1]\n",
    "    patient[\"EncodedPixels\"] = encoded_pixels\n",
    "  except:\n",
    "    remove.append(\"/content/drive/MyDrive/siim-acr-pneumothorax/pneumothorax/dicom-images-train/\" + data.StudyInstanceUID + \"/\" + data.SeriesInstanceUID + \"/\" + data.SOPInstanceUID + \".dcm\")\n",
    "  patient[\"Age\"] = data.PatientAge\n",
    "  patient[\"Sex\"] = data.PatientSex\n",
    "  patient[\"Modality\"] = data.Modality\n",
    "  patient[\"BodyPart\"] = data.BodyPartExamined\n",
    "  patient[\"ViewPosition\"] = data.ViewPosition\n",
    "  patient[\"path\"] = \"/content/drive/MyDrive/siim-acr-pneumothorax/pneumothorax/dicom-images-train/\" + data.StudyInstanceUID + \"/\" + data.SeriesInstanceUID + \"/\" + data.SOPInstanceUID + \".dcm\"\n",
    "  patients.append(patient)\n",
    "\n",
    "patients_train = pd.DataFrame(patients,columns=[\"EncodedPixels\",\"path\"])\n",
    "patients_train=patients_train.loc[~patients_train['path'].isin(remove)] #remove rows which do not have images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "6de5750160214b838b9de7acf82f603b",
      "e2acd9121b094b48988d82b8f36018c3",
      "ed92561dfba64dc4931a4fdf69a68bb4",
      "dc5b84c322704f9ba6a7aa9f8dc89036",
      "12bcf0842ee341b6beae8a1a29d8f4f7",
      "780a680d651b472bb6daddfa82e3a88d",
      "b3856f3ef38440b293ae1d4f10ae421f",
      "16b5ca2c3dfb48438dce6c93a87350ee"
     ]
    },
    "id": "00dLj7w-8nWw",
    "outputId": "73b5ff6b-c95f-4d25-c0f7-e0ffe1d51a9b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6de5750160214b838b9de7acf82f603b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10685.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_path=[]\n",
    "train_encoded_pixel=[]\n",
    "test_path=[]\n",
    "test_encoded_pixel=[]\n",
    "train_len=len(patients_train)-int(len(patients_train)*0.2) #We are dividing the data into train and test\n",
    "test_len=int(len(patients_train)*0.2)\n",
    "count=0\n",
    "for i in tqdm(range(0,len(patients_train))):\n",
    "  if count<=train_len:\n",
    "    train_path.append(list(patients_train['path'].values)[i])\n",
    "    train_encoded_pixel.append(list(patients_train['EncodedPixels'].values)[i])\n",
    "    count=count+1\n",
    "  else:\n",
    "    test_path.append(list(patients_train['path'].values)[i])\n",
    "    test_encoded_pixel.append(list(patients_train['EncodedPixels'].values)[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzo7U7migGMR"
   },
   "source": [
    "# **Function 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "P3tg0zf_87g0"
   },
   "outputs": [],
   "source": [
    "#Function-1\n",
    "def final_fun_1(X):\n",
    "  img = tf.io.read_file(X)\n",
    "  image = tfio.image.decode_dicom_image(img, dtype=tf.uint8,color_dim=True,scale='preserve')\n",
    "  image = tf.image.convert_image_dtype(image, tf.float32)#converting the image to tf.float32\n",
    "  image=tf.squeeze(image,[0]) #squeezing the image because the file is of the shape(1,1024,1024,1) and we want (1024,1024,3)\n",
    "  b = tf.constant([1,1,3], tf.int32)\n",
    "  image=tf.tile(image,b)#the image is of the shape (1024,1024,1) to make it (1024,1024,3) I am using tf.tile\n",
    "  image=tf.image.resize(image,size=[256,256])\n",
    "  image=tf.expand_dims(image,axis=0)\n",
    "   #recall\n",
    "  if model.predict(image)>=0.5:\n",
    "    print(\"Pneumothorax has been detected\")\n",
    "    mask=final.predict(image)\n",
    "    mask=(mask>0.5).astype(np.uint8)\n",
    "    plt.figure(figsize=(20,6))\n",
    "    plt.title(\"Mask\")\n",
    "    return plt.imshow(np.squeeze(mask),cmap='gray')\n",
    "  else:\n",
    "    return \"No Pneumothorax Detected\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lz5SjRfygAvx"
   },
   "source": [
    "# **Function 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "oGaQ0n5L-Op1"
   },
   "outputs": [],
   "source": [
    "def final_fun_2(X,Y):\n",
    "  img = tf.io.read_file(X)\n",
    "  image = tfio.image.decode_dicom_image(img, dtype=tf.uint8,color_dim=True,scale='preserve')\n",
    "  image = tf.image.convert_image_dtype(image, tf.float32)#converting the image to tf.float32\n",
    "  image=tf.squeeze(image,[0]) #squeezing the image because the file is of the shape(1,1024,1024,1)and we want (1024,1024,3)\n",
    "  b = tf.constant([1,1,3], tf.int32)\n",
    "  image=tf.tile(image,b)#the image is of the shape (1024,1024,1) to make it (1024,1024,3) and for this using tf.tile\n",
    "  image=tf.image.resize(image,size=[256,256])\n",
    "  image=tf.expand_dims(image,axis=0)\n",
    "  if Y!=\" -1\":\n",
    "    print(\"Ground truth of Classification is 1(Has Pneumothorax)\")\n",
    "    print('*'*100)\n",
    "  else:\n",
    "    print(\"Ground truth of Classification is 0(Does not have Pneumothorax)\")\n",
    "    print(\"Ground truth of Segmentation -- There is no mask\")\n",
    "    print('*'*100)\n",
    "\n",
    "    \n",
    "  if model.predict(image)>=0.5:\n",
    "    print(\"Pneumothorax has been detected\")\n",
    "    mask=final.predict(image)\n",
    "    mask=(mask>0.5).astype(np.uint8)\n",
    "    try:\n",
    "      true_mask=Image.fromarray(mask_functions.rle2mask(Y,1024,1024).T).resize((256,256), resample=Image.BILINEAR)\n",
    "      true_mask=np.array(true_mask)\n",
    "      plt.figure(figsize=(20,6))\n",
    "      plt.subplot(121)\n",
    "      plt.title(\"X-ray image with mask(Ground truth)\")\n",
    "      plt.imshow(np.squeeze(image),cmap='gray')\n",
    "      plt.imshow(np.squeeze(true_mask),cmap='gray',alpha=0.3)\n",
    "      plt.subplot(122)\n",
    "      plt.title(\"X-ray image with mask(Predicted)\")\n",
    "      plt.imshow(np.squeeze(image),cmap='gray')\n",
    "      plt.imshow(np.squeeze(mask),cmap='gray',alpha=0.3)\n",
    "      return plt.show()\n",
    "    except: #if there is no ground truth mask\n",
    "      plt.figure(figsize=(20,6))\n",
    "      plt.title(\"X-ray image with mask(Predicted)\")\n",
    "      plt.imshow(np.squeeze(image),cmap='gray')\n",
    "      plt.imshow(np.squeeze(mask),cmap='gray',alpha=0.3)\n",
    "      return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WFSVFIMOHmd7",
    "outputId": "30531d52-9d1e-4512-faf2-e1e25133d710"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2136\n"
     ]
    }
   ],
   "source": [
    "print(len(test_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M317OxJ6f7OD"
   },
   "source": [
    "# **Define the Metric**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "aI9ktZsHN4zt"
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "  y_true_f = K.flatten(y_true)\n",
    "  y_pred_f = K.flatten(y_pred)\n",
    "  intersection = K.sum(y_true_f * y_pred_f)\n",
    "  return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "qzbYch4S_XTQ"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "#Selecting a random value from the test data\n",
    "rand_id = random.randrange(0,len(test_path))\n",
    "# rand_id = np.random.randint(len(test_path))\n",
    "# print(rand_id)\n",
    "model=load_model('/content/drive/MyDrive/siim-acr-pneumothorax/pneumothorax/densenet121_weights-33-0.9072.hdf5')\n",
    "final=tf.keras.models.load_model('/content/drive/MyDrive/siim-acr-pneumothorax/pneumothorax/unet_with_densenet_weights-23-0.4608.hdf5',custom_objects={'dice_coef':dice_coef})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rloEnDsn_v7S",
    "outputId": "62924605-9fbc-46d6-aadd-939ea74fef10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.4749116897583008 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "final_fun_1(test_path[rand_id])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N3eGWaVpH31m",
    "outputId": "37030ab4-419a-4821-e798-d131f83ccb74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth of Classification is 0(Does not have Pneumothorax)\n",
      "Ground truth of Segmentation -- There is no mask\n",
      "****************************************************************************************************\n",
      "--- 0.0878300666809082 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "final_fun_2(test_path[rand_id],test_encoded_pixel[rand_id])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PCCFyzK89MSO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Final_casestudy_pneumothorax.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "12bcf0842ee341b6beae8a1a29d8f4f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "16b5ca2c3dfb48438dce6c93a87350ee": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6de5750160214b838b9de7acf82f603b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ed92561dfba64dc4931a4fdf69a68bb4",
       "IPY_MODEL_dc5b84c322704f9ba6a7aa9f8dc89036"
      ],
      "layout": "IPY_MODEL_e2acd9121b094b48988d82b8f36018c3"
     }
    },
    "780a680d651b472bb6daddfa82e3a88d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3856f3ef38440b293ae1d4f10ae421f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dc5b84c322704f9ba6a7aa9f8dc89036": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16b5ca2c3dfb48438dce6c93a87350ee",
      "placeholder": "​",
      "style": "IPY_MODEL_b3856f3ef38440b293ae1d4f10ae421f",
      "value": " 10685/10685 [00:22&lt;00:00, 471.02it/s]"
     }
    },
    "e2acd9121b094b48988d82b8f36018c3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed92561dfba64dc4931a4fdf69a68bb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_780a680d651b472bb6daddfa82e3a88d",
      "max": 10685,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_12bcf0842ee341b6beae8a1a29d8f4f7",
      "value": 10685
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
